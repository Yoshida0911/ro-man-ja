\section{緒言}
近年，少子高齢化の進行は深刻な社会問題となっており，慢性的な労働力不足を招いている．
このような背景のもと，労働力不足の代替への需要の高まりとロボット技術の進歩に伴い，移動ロボットは物流やサービス分野をはじめとする産業において，多様な業務を効率的に遂行することが期待されている\cite{alatise2020review}．
こうしたロボットは，人間中心環境へとますます統合されるにつれ，安全性および効率性を確保しつつ，社会規範に適合したナビゲーションの実現が重要な課題となっている．
従来のナビゲーション技術は，LiDAR（Light Detection and Ranging）やカメラなどのセンサを用いて環境を認識し，障害物を回避しながら目的地に到達することに焦点を当ててきた．
このアプローチは，ロボットが物理的な環境を理解し，安全に移動するための基盤技術として有効である．
しかしながら，幾何学的情報に基づくものであり，周囲の人間の行動や社会的状況といった文脈情報を十分に考慮することは困難である．

Vision Language Model（VLM）やLarge Language Model（LLM）の発展により，ゼロショット物体認識や高度な言語理解，視覚と言語のグラウンディングが可能となった．
これにより，LLMとロボットを接続する研究も数多く報告されている\cite{lin2024drplanner, kwon2024language, shao2024lmdrive}．
一方で，数値最適化やリアルタイムな軌道生成そのものにLLMを直接担わせるアプローチは，計算負荷や安全性，運動的制約の扱いといった観点から依然として課題が多い．
LLMは推論や一般知識の活用には優れるものの，ミリ秒単位の制御周期で動作する低レイヤの数値計算や，パラメータの微調整を行うことは得意ではない．

したがって，人間中心環境における安全かつ効率的なナビゲーションを実現するためには，高レベルの意味理解と低レベルの数値的に安定した制御手法を適切に分離・統合することが重要である．
本研究では，VLMが文脈依存のナビゲーション方針のみを決定し，下位レイヤのアルゴリズムはその方針を自身の評価関数に反映する構造を採用する．
これにより，既存のアルゴリズムを大きく変更することなく，多様なナビゲーションモジュールへ適用可能な汎用的枠組みを実現する．
具体的には，ロボットに搭載されたカメラから得られた視覚情報に加え，指向性マイクから得られた音響情報を入力とし，「配送ロボット」や「人助けロボット」といったロボットの役割を高レベル指示として与える．
VLMは，これらの情報に基づいて，走行方針を表す少数のパラメータを生成する．
下位レイヤでは，従来どおりセンサ情報に基づいて環境を認識し，障害物を回避しながら目的地に到達するが，VLMから生成されたパラメータを評価関数に組み込むことで，役割および環境文脈に応じたナビゲーションを実現する．

本研究では，この枠組みのうち，局所的経路計画に着目し，人工ポテンシャル法（Artificial Potential Field）に対して，VLMによるパラメータ生成を統合する手法を提案する．
これにより，少数のパラメータを文脈に応じて変更することで，走行特性を文脈依存的に切り替えることを可能とする．
本手法の有効性は，実機ロボットを用いた実験により検証する．