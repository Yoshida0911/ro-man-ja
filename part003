\section{文脈依存パラメータによるポテンシャル場に基づく局所的ナビゲーション手法}
提案手法の概要を\cref{fig:system_1}に示す．
本手法は大きく３つのステップから構成される．

まず，ロボット前方に搭載されたRGBカメラから環境画像を取得し，YOLOを用いて画像内の対象物体を検出する．
指向性マイクから音響強度地図を取得し，音響強度が所定の閾値を超える場合にはヒートマップとして検出結果画像に重畳する．
また，音響が存在しない場合には，検出結果画像のみを用いる．

次に，検出された各対象物体の情報と環境全体を含む認識画像を，ロボットの役割を示すプロンプトとともにVLMに入力する．
VLMは，視覚情報，音響情報およびロボットの役割情報を統合的に解釈し，各物体に対してのポテンシャル法に用いるパラメータを出力する．

本研究では，引力および斥力に関わる２つの重み係数を導入する．
引力に対する重みを$W_{prog}$，斥力に対する重みを$W_{obst, i}$と定義する．
$W_{prog}$はゴールへの指向性を表し，$W_{obst, i}$は対象物体に対する警戒度を表す．
さらに，各対象物体に対して，接近・回避の意図を表すフラグ$flag \in \{1,-1\}$を生成する．
$flag=1$は対象物体への接近を，$flag=-1$は回避を意味する．
生成されたパラメータは共有メモリを介して局所的ナビゲーションモジュールに送信される．
対象物体ごとに重み係数および意図フラグを動的に変更し，ポテンシャル場に反映することで，安全重視の大回り回避や効率重視の近傍通過，あるいは対象物体への積極的な接近といった挙動を，対象の属性や環境文脈に応じて生成可能となる．

ロボットに作用する合力ベクトル$\mathbf{F}$は，式(\ref{eq:force})に示すように，
\begin{equation}
  \label{eq:force}
  \mathbf{F} = W_{\mathrm{prog}}\, \mathbf{F}_{\mathrm{att}} + \mathbf{F}_{\mathrm{rep}}^{\mathrm{total}}
\end{equation}
\begin{equation}
\mathbf{F}_{\mathrm{rep}}^{\mathrm{total}}
=
\sum_i
\begin{cases}
W_{\mathrm{obst},i}\,\mathbf{F}_{\mathrm{rep},i}
& (flag_i = -1) \\[6pt]
- W_{\mathrm{obst},i}\,\mathbf{F}_{\mathrm{rep},i}
& (flag_i = 1)
\end{cases}
\end{equation}
で与えられる．
ここで，$\mathbf{F}_{\mathrm{att}}$はゴールへの引力ベクトルを表す．
本手法では，VLMが各対象物体$i$に対して，斥力重み$W_{\mathrm{obst},i}$および意図フラグ$flag_i$に加え，進行方向への引力重み$W_{\mathrm{prog},i}$を個別に出力する．
ロボットはナビゲーション中，自身の影響範囲内にある最も近い対象物体の$W_{\mathrm{prog},i}$を動的に現在地の$W_{\mathrm{prog}}$として採用する．
これにより，対峙している物体の文脈に合わせて，ゴールへの推進力を柔軟に調整可能としている．
また，$\mathbf{F}_{\mathrm{rep}}^{\mathrm{total}}$は検出された対象物体からの斥力の総和であり，
各対象物体$i$に対してVLMが生成する斥力重み$W_{\mathrm{obst},i}$および意図フラグ$flag_i$に基づいて計算される．
$flag_i$は接近・回避の意図を表し，$flag_i=1$を接近（approach），$flag_i=-1$を回避（avoid）と定義する．
$flag_i$に応じて物体$i$に対する斥力項の符号を切り替えることで，回避対象の場合は通常の斥力を与え，
接近対象の場合は斥力項を反転させ，疑似的な引力として作用させる．

本手法の特徴は，ポテンシャル場の数理構造自体は変更せず，重み係数のみを文脈依存的に動的調整する点にある．
これにより，既存の局所的ナビゲーションアルゴリズムとの整合性を保ちながら，高次の意味理解を低レイヤ制御へ直接反映することが可能となる．
