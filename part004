\section{実験}
\subsection{実験条件}
提案手法の有効性を評価するため，屋内環境である宇都宮大学陽東キャンパスREALにおいて自律走行実験を行った．
実験には，\cref{fig:hirume}に示す自律移動ロボットを使用した．
ロボット前方には環境画像取得用のRGBカメラ（Logicool C920n）を搭載し，さらに音源方向および音響強度分布の取得のため指向性マイク（Sipeed R6+1 Microphone Array）を搭載した．
その他の仕様を\cref{tab:robot_specifications}に示す．
物体検出にはYOLO26nを使用し，視覚言語モデル（VLM）にはOpenAI社のGPT-5.1をAPI経由で用いた．

\begin{figure}[t]
    \centering
    \includegraphics[width=0.8\columnwidth]{figures/hirume.png}
    \caption{Robot used in the experiment}
    \label{fig:hirume}
\end{figure}

\begin{table}[htbp]
    \centering
    \scriptsize
    \caption{Robot specifications}
    \label{tab:robot_specifications}
    \begin{tabular}{c|c}
        \hline
        Hardware & Model Number \\
        \hline
        Size [m] & Width  = 0.55 \\
                 & Depth  = 0.80 \\
                 & Height = 0.80 \\
        Weight [kg] & 80.0 \\
        PC &  Ryzen 5 5560U (AMD) \\
        IMU & ICM-20948 (TDK InvenSense) \\
        3D-LiDAR & Mid-360 (Livox), XT-32 (Hesai) \\      
        2D-LiDAR & RPLIDAR S2 x2 (SLAMTEC)\\
        Motor & BLH5100K-A (Oriental Motor)\\
        Motor Driver/Encoder & BLWR5100K-50FR (Oriental Motor) \\ 
        Battery & IFM24-400E2 (O’ cell)\\
        \hline
    \end{tabular}
\end{table}

本実験では，ロボットの役割の違いがVLMにより生成されるポテンシャル場パラメータおよび局所的ナビゲーション挙動に与える影響を評価するため，ロボットに以下の３種類の役割を与えた．

\begin{small}
\begin{itemize}
    \item 配達ロボット：荷物を安全かつ効率的に目的地へ運搬する
    \item 人支援ロボット：困っている人物へ接近し支援を行う
    \item 警備ロボット：周囲を監視し異常を確認する
\end{itemize}
\end{small}

ロボットの初期位置から前方3.0\,mおよび5.0\,mの２箇所に障害物を設置し，障害物は人物およびコーンとした．
なお，人工ポテンシャル法における各対象物体の有効影響距離は 2.0\,mに固定した．
手前と奥の配置を入れ替えた複数のパターンを用意することで，対象物体の種類および位置関係がVLMによるパラメータ生成および走行軌道に与える影響を検証した．
また，人物近傍に音源が存在する条件と，音源が存在しない条件を設定し，音響情報が生成パラメータおよび走行挙動に与える影響を評価した．
具体的には，対象物体の種類，位置関係，および音響情報の有無の組み合わせとして，以下の5つのケースを設定した．

\begin{small}
\begin{itemize}
    \item ケース1：手前および奥の双方にコーンを配置した条件
    \item ケース2：手前にコーン，奥に人物（音源なし）を配置した条件
    \item ケース3：手前に人物（音源なし），奥にコーンを配置した条件
    \item ケース4：手前にコーン，奥に人物（音源あり）を配置した条件
    \item ケース5：手前に人物（音源あり），奥にコーンを配置した条件
\end{itemize}
\end{small}

各条件において，環境画像および音響強度地図を取得した後，VLMにより各対象物体に対する引力重み $W_{\mathrm{prog}}$，斥力重み $W_{\mathrm{obst},i}$，および接近・回避を表すフラグ $flag_i$ を生成した．
なお，VLM出力のばらつきによる影響を排除するため，各条件において一度生成されたパラメータは走行中は固定値として扱った．

\subsection{VLMによるパラメータ生成結果と局所的ナビゲーション}
本節では，提案手法における VLM のパラメータ生成の妥当性と，それに基づくナビゲーション挙動を評価する．
比較対象として，VLM を使用せず，固定パラメータを用いた従来の人工ポテンシャル法（以下，ベースライン手法）\cite{khatib1986real}による走行実験も実施した．

\subsubsection{文脈に応じたパラメータの生成結果}
まず，ロボットの役割および環境条件（対象物体の種類，音響情報の有無）の変化に対し，VLM が生成したポテンシャル場パラメータ（$W_{\mathrm{prog}}$, $W_{\mathrm{obst},i}$, $flag_i$）の結果を\cref{tab:parameter_results}に示す．
実験の結果，対象物体がコーンの場合，役割に関わらず全ての条件で$flag_i=-1$（回避）が出力され，障害物として認識された．
一方，人物が存在するケース（ケース２～５）では，役割と音響情報の有無によってパラメータに顕著な変化がみられた．

具体的には，「配送ロボット」では音響情報の有無に関わらず，全ての対象に対して$flag_i=1$を出力し，配送効率を優先した回避行動を選択した．
しかし，無音・有音に関わらず，人物に対してはコーンよりも強い斥力重みを設定する傾向が見られ，人間に対してより安全マージンを確保しようとする意図が確認できる．
「人支援ロボット」は，人物に対して音響の有無に関わらず一貫して$flag_i=1$（接近）を出力し，支援対象として認識した ．
特に注目すべきは，「警備ロボット」におけるパラメータの変化である．
警備ロボットは，無音の人物（ケース2，3）に対しては$flag_i=-1$（回避）を選択して通常の巡回を継続したのに対し，音響情報が存在する人物（ケース4，5）に対しては$flag_i=1$（接近）へと行動を変化させた ．
これは，VLMが視覚情報と音響情報をマルチモーダルに統合して解釈し，役割に応じた論理的なパラメータ変更を行ったことを示している．
ゆえに，提案手法は同一な環境入力に対しても，与えられた役割（プロンプト）に応じて異なるナビゲーション方針を導出可能であることが確認された．

\subsubsection{走行軌跡によるナビゲーション評価}
次に，生成されたパラメータを適用した際のそれぞれのケースにおけるロボットの走行軌跡を\cref{fig:trajectory}に示す．
図中にはベースライン手法による軌跡（点線）と，提案手法による軌跡（実線）を重ねて表示している．
ベースライン手法では，環境の文脈に関わらず全ての障害物に対して一定の距離を保ちながら回避する挙動が確認された．
一方，提案手法では役割と文脈に応じた特徴的な軌跡の分岐が生成された．
対象が全てコーンであるケース1では，全役割のロボットが回避軌跡を生成した（\cref{fig:case1}）．
しかし，人物が含まれるケースにおいて挙動の差が明確に表れた．
例えば，無音の人物が存在するケース2および3では，配達ロボットと警備ロボットが人物を回避する軌跡を生成したのに対し，人支援ロボットは疑似的な引力（$flag_i=1$）の作用により人物へ接近する軌跡を描いた（\cref{fig:case2,fig:case3}）．
さらに，音響情報が付加されたケース4および5では，警備ロボットの軌跡が回避から接近へと明確に変化し，音源対象の確認へ向かう挙動が実現された（\cref{fig:case4,fig:case5}）．

以上の結果より，提案手法は視覚と音響のマルチモーダルな文脈をVLMによって解釈し，ポテンシャル場の重みおよび引力・斥力の反転フラグという物理的パラメータへ落とし込むことで，
単一のナビゲーションアルゴリズムでありながら，役割と環境文脈に即した多様かつ社会的に適切な走行軌跡を生成可能であることを実証した．
